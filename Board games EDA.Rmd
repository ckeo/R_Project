---
title: "Board games project"
output: html_document
date: '2022-05-04'
---
Note: 
"In all uses of the BGG XML API, you shall credit BoardGameGeek by name as the source of the data."

https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-01-25/readme.md

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
#install.packages("wesanderson")
library(wesanderson)
library(stringr)
library(forcats)
```


```{r}

ratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/ratings.csv')
details <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/details.csv')

head(details)
head(ratings)

ratings %>%
  arrange(desc(bayes_average))
```

My initial data questions are...
Which game has the highest average? What are the characteristics of the top 100 games? Games by age group? most user ratings? 

Should I get rid of games with like less than 100 reviews?

Maybe I can make a recommendation system based on how many people you have, how much time, how old (like over under 12 or something) and what kind of games you like?

I guess in theory I could do multilinear regression.

General questions about the data:
what is bayes average? Think it weights number of samples. So for example a game with three reviews but they're all 10s isn't number 1.
do i need to get rid of the []s in my data probably. am i even gonna use those cols tho. Oh is it just a list within a column? Could be good.
How do I deal with double counting for example if a game is "city building" and "medieval"
what is wanting vs wishing in the ratings db? -- seems like wishing is if its on someones wishlist, wanting is if they are actively looking to trade someone for it. Wishing seems more useful then.


On the rating system:

"There are three rating systems you will see on the site:
User Rating (aka Your Rating): doesnt matter here
Average Rating: The average of all the ratings from registered BGG users, calculated by adding up the individual ratings and dividing by the number of ratings. You will see this rating listed in advanced searches and near the top of game pages.
BGG Rating (aka Geek Rating): BoardGameGeek's ranking charts are ordered using the BGG Rating, which is based on the Average Rating, but with some alterations. To prevent games with relatively few votes climbing to the top of the BGG Ranks, artificial "dummy" votes are added to the User Ratings. These votes are currently thought to be 100 votes equal to the mid range of the voting scale: 5.5, but the actual algorithm is kept secret to avoid manipulation. The effect of adding these dummy votes is to pull BGG Ratings toward the mid range. Games with a large number of votes will see their BGG Rating alter very little from their Average Rating, but games with relatively few user ratings will see their BGG Rating move considerably toward 5.5. This is known as "Bayesian averaging" and a quick search of both BGG and/or the Web will reveal much discussion on the topic. You will see this rating listed in advanced searches, your game collection, and near the top, most right corner of game pages.



```{r}

#interesting to see the two rating systems. I dont really want to but I could also do my own rating system of sorts
#where I use the real average but only include games with at least however many reviews
ratings %>%
  ggplot(aes(x = bayes_average)) + geom_histogram()

ratings %>%
  ggplot(aes(x = average)) + geom_histogram(fill = c(wes_palette(n = 1, name = "Zissou1"))) +labs(title = "Distribution of Average Ratings") + scale_x_continuous(name="Average User Rating") + scale_y_continuous(name="Count")


```
I should also look at a graph of number of reviews and make a cutoff maybe? They already have that you must have at least 30 reviews to be included though. and the median number of reviews is 122.

```{r}
ggplot(data = ratings, aes(x = users_rated)) + geom_histogram(bins = 100) + scale_x_continuous(limits = c(0,2000))

median(ratings$users_rated)


```





Combine the datasets here:

```{r}
combo = ratings %>%
  inner_join(details, by = "id")
```

checking to make sure all the games are matching up 
```{r}
combo %>%
  filter(name != primary)

#only five dont match up and its mostly because of quotation marks or $ weird characters
```


Removing unecessary columns
```{r}
games = combo %>%
  select(-c(url, thumbnail,boardgamefamily, boardgameimplementation, num.y, primary, yearpublished))
```



Looks like some games have 0 in playingtime but a value in minplaytime. Lets assign that to the playingtime when playingtime is 0. I forget how tho. could def do mutate but kind of annoying.

```{r}
sum(games$playingtime == 0 & games$minplaytime == 0)
sum(games$minplaytime == 0)

```


Maybe remove useless rows seems like when a bunch of cols are 0 the rows are usually not meaningful?

```{r}
games = games %>%
  filter(year != 0 | playingtime != 0 | minplayers != 0)

#This only removes six rows but they were def useless rows

```

```{r}
games %>%
  ggplot(aes(x = owned)) + geom_histogram(fill = c(wes_palette(n = 5, name = "Zissou1")[5]), bins = 100) +labs(title = "Distribution of Number of Users Owning the Games") + scale_x_continuous(name="Number of Users Marking Game as 'Owned'") + scale_y_continuous(name="Count")

```



figuring out what to do about really long games

```{r}
games %>%
  ggplot(aes(y = playingtime)) + geom_boxplot()

games %>%
  filter(playingtime < 8000) %>%
  ggplot(aes(y = playingtime)) + geom_boxplot()

10000/60
#thats 166 hours. I know people can game forever but uh I dont think thats right.

#maybe min playing time is better to look at

games %>%
  filter(minplaytime < 500) %>%
  ggplot(aes(y = minplaytime)) + geom_boxplot()

#not really honestly

level_order = c('Very Short (<15 min)', 'Short (15-30 min)', 'Medium (30-60 min)', 'Long (60-120 min)', 'Very Long (120-240 min)', 'More than 240 min')

#how do I sort the bars? probably something about factors
games_ptcleaned = games %>%
  filter(playingtime > 0) %>%
  mutate(game_lengths = ifelse(playingtime < 15, "Very Short (<15 min)", ifelse(playingtime < 30, "Short (15-30 min)", ifelse(playingtime < 60, "Medium (30-60 min)", ifelse(playingtime < 120, "Long (60-120 min)", ifelse(playingtime < 240, "Very Long (120-240 min)", "More than 240 min"))))))

games_ptcleaned %>%
  ggplot(aes(x = factor(game_lengths, level = (level_order)))) + geom_bar(fill = c(wes_palette(n = 5, name = "Darjeeling1"), wes_palette(n = 4, name = "GrandBudapest2")[4])) + coord_flip() + labs(title = "Board Game Lengths") + scale_x_discrete(name="Board Game Length") + scale_y_continuous(name="Count")




#probably there should be a reason I picked these increments. They just seemed good to me. I guess rather than dealing with the 60000 hour game I am just assuming its really long and putting it in the really long category.




```



I think i will start with the easier ones before tackling category lol

Looking at playing time here and ratings?


```{r}

games_ptcleaned %>%
    ggplot(aes(x = factor(game_lengths, level = level_order), y = average)) + geom_boxplot(fill = c(wes_palette(n=5, name="Darjeeling1"), wes_palette(n = 4, name = "GrandBudapest2")[4])) + labs(title = "Average User Scores by Game Length", ylab = "User Scores") + scale_x_discrete(name="Board Game Length")  + scale_y_continuous(name = "Average User Score") + coord_flip()
  
games_ptcleaned %>%
  ggplot(aes(x = factor(game_lengths, level = level_order), y = bayes_average)) + geom_boxplot(fill = c(wes_palette(n=5, name="FantasticFox1"), wes_palette(n = 1, name = "Zissou1"))) + labs(title = "Bayesian Average User Scores by Game Length") + scale_x_discrete(name="Board Game Length")  + scale_y_continuous(name = "Bayesian Average User Scores")


anova = aov(average ~ game_lengths, data = games_ptcleaned)
summary(anova)
#so according to anova at least one of the means is significantly different. Got a warning about something being unbalanced tho. Some of the groups are much larger than others so could be the problem.

```
How about same plot for number owned/wished

```{r}
games_ptcleaned %>%
  filter(owned > 1000) %>%
    ggplot(aes(x = factor(game_lengths, level = level_order), y = owned)) + geom_boxplot(fill = c(wes_palette(n=5, name="FantasticFox1"), wes_palette(n = 1, name = "Zissou1"))) + labs(title = "Number of Users Marking as 'Owned' by Game Length") + scale_x_discrete(name="Board Game Length")  + scale_y_continuous(name = "Number of Users Marking as Owned") + coord_flip()

games_ptcleaned %>%
    ggplot(aes(x = factor(game_lengths, level = level_order), y = wishing)) + geom_boxplot(fill = c(wes_palette(n=5, name="FantasticFox1"), wes_palette(n = 1, name = "Zissou1"))) + labs(title = "Average User Scores by Game Length", ylab = "User Scores") + scale_x_discrete(name="Board Game Length")  + scale_y_continuous(name = "Average User Score") + coord_flip()
```


Do rating and own/wish correlate?

```{r}
ggplot(games_ptcleaned, aes(x = average, y = owned)) + geom_point() + geom_density2d() + labs(title = "Number of Users with Game marked as 'Owned' Vs. Average User Rating") + scale_x_continuous(name = "Average User Rating") + scale_y_continuous(name = "Number of Users with Game marked 'Owned'") + geom_hline(linetype = "dashed", color = 'red', yintercept = 10000)

summary(lm(owned ~ average, data = games_ptcleaned))

ggplot(games_ptcleaned, aes(x = average, y = wishing)) + geom_point() + labs(title = "Number of Users with Game on Wishlist Vs. Average User Rating") + scale_x_continuous(name = "Average User Rating") + scale_y_continuous(name = "Number of Users with Game on Wishlist")

summary(lm(wishing ~ average, data = games_ptcleaned))

ggplot(games_ptcleaned, aes(x = average, y = wishing)) + labs(title = "Number of Users with Game on Wishlist Vs. Average User Rating") + scale_x_continuous(name = "Average User Rating") + scale_y_continuous(name = "Number of Users with Game on Wishlist") + geom_point() + geom_density2d() 

ggplot(games_ptcleaned, aes(x = average, y = wishing)) + geom_point() + geom_density2d()

```





Attempt at regression lol

```{r}
remove_worst_outliers = games %>%
  filter(playingtime < 10000 & playingtime > 0 & year < 2023)

model = lm(average~playingtime + minage + year, remove_worst_outliers)

summary(model)

avPlots(model)

plot(model)

#ha ha. This doesn't really get me anything but that's ok.
```


Year vs year published??

Pretty much the same


Ok going to try to look at the categories. weeee

```{r}
#just figuring out what to do here

class(games$boardgamecategory)

test = games$boardgamecategory[2]
test
test = gsub(x = test, pattern = "'", replacement = "")
test
test = gsub(x = test, pattern = '\\[', replacement = '')
test
test = gsub(x = test, pattern = '\\]', replacement = '')
test
str_split(test, ", ")

```

Go time, trying to make all the category column into a list

```{r}

games$boardgamecategory = gsub("'", "", as.character(games$boardgamecategory))

games$boardgamecategory = gsub("\\[", "", as.character(games$boardgamecategory))

games$boardgamecategory = gsub("\\]", "", as.character(games$boardgamecategory))

games$boardgamecategory = gsub('"', '', as.character(games$boardgamecategory))

games$boardgamecategory = str_split(games$boardgamecategory, ", ")

head(games)

sum(!is.na(unique(unlist(games$boardgamecategory))))
#84 different categories of boardgames. Which are the top 20 or so?



```

```{r}
#find top 20 most common game types

df = data.frame(category = unlist(games$boardgamecategory))

df %>%
  count(category) %>%
  mutate(perc = n/nrow(df)) %>%
  arrange(desc(perc)) %>%
  ggplot(aes(x = fct_reorder(category, perc), y = perc)) + geom_col() + labs(ylab = "% of total categories")


#looks like there is a drop off in the graph around .015.

df %>%
  count(category) %>%
  mutate(perc = n/nrow(df)) %>%
  arrange(desc(perc)) %>%
  filter(perc > .015) %>%
  ggplot(aes(x = fct_reorder(category, perc), y = perc)) + geom_col(fill = wes_palette(n=4, name="GrandBudapest2")[4]) + labs(title = "Top Game Categories (Make up over 1.5% of all categories)") + scale_x_discrete("Category") + scale_y_continuous("Percent of Total Categories") +coord_flip()



top_cats = df %>%
  count(category) %>%
  mutate(perc = n/nrow(df)) %>%
  arrange(desc(perc)) %>%
  filter(perc > .015)

top_cats = top_cats[[1]]


```


```{r}

#for loop through the top categories like this to create new category columns
#sapply(games$boardgamecategory, function(lst) as.numeric("Medieval" %in% lst))


for (cat in top_cats)
{
  
  new = sapply(games$boardgamecategory, function(lst) as.numeric(cat %in% lst))
  games[ , ncol(games) + 1] = new
  colnames(games)[ncol(games)] = as.character(cat)

}

#yay! have 21 new columns with 0 and 1s saying if something has the category type. Honestly wouldn't be huge deal to do more categories than this.
```

Average rating per category type? If using in a slide def acknowledge that most games have more than one category listed

```{r}
#I think I might need to do a for loop for this too? For loop and dplyr!??!

#initialize data frame so i can rbind. Couldn't figure out how to do an empty dataframe so i guess I will just create a row and delete later
# cat_stats = data.frame(matrix(ncol = 3, nrow = 0))
# x = c("median_rating", "sd_rating", "Category")
# colnames(cat_stats) = x
cat_stats = data.frame(Category = "", median_rating = 0, mean_rating = 0, sd_rating = 0, median_owned = 0, mean_owned = 0, sd_owned = 0, median_wishing = 0, mean_wishing = 0, sd_wishing = 0)
for (cat in top_cats) {
  cat_stat = games %>%
  filter(games[cat] == 1) %>%
  summarise(median_rating = median(average), mean_rating = mean(average), sd_rating = sd(average), median_owned = median(owned),  mean_owned = mean(owned), sd_owned = sd(owned), median_wishing = median(wishing), mean_wishing = mean(wishing), sd_wishing = sd(wishing))
  cat_stat$Category = as.character(cat)
  cat_stats = rbind(cat_stats, cat_stat)
}

cat_stats = cat_stats %>%
  filter(Category != "")

cat_stats
```
Wowza means are pretty different than the medians for owned and wishing. Much higher. data must be skewed right. Certain games must have a ton more people reporting they own/wish for the games.
Lets graph the cat_stats for rating. How to graph something with median and sd??

```{r}

ggplot(cat_stats, aes(x = fct_reorder(Category, mean_rating), y = mean_rating)) + geom_bar(position = position_dodge(), stat = 'identity', fill = wes_palette(n=4, name="GrandBudapest2")[4]) + geom_errorbar(aes(ymin = mean_rating - sd_rating, ymax = mean_rating + sd_rating), width = .2) + coord_flip() + labs(title = "Average User Scores by Game Category") + scale_x_discrete(name="Board Game Category")  + scale_y_continuous(name = "Average User Rating")

```

```{r}
ggplot(cat_stats, aes(x = fct_reorder(Category, mean_owned), y = mean_owned)) + geom_bar(position = position_dodge(), stat = 'identity', fill = wes_palette(n=5, name="FantasticFox1")[3]) + geom_errorbar(aes(ymin = mean_owned - sd_owned, ymax = mean_owned + sd_owned), width = .2) + coord_flip() + labs(title = "Average Number of Users Owning Game by Category") + scale_x_discrete(name="Board Game Category")  + scale_y_continuous(name = "Average Number of Users Owning Game")

#ha ha this is not very useful
#should I have made a cutoff of games must be owned by at least 100 people or something?

#maybe try a boxplot instead? This will have to be of the raw data except duplicate rows with more than one category?? no... idk how to do this

test_med = games %>%
  filter(Medieval == 1)

test_fan = games %>%
  filter(Fantasy == 1)

test_med + test_fan + ggplot(data = ) geom_boxplot()

#this isn't going to work cuz all I have are means median and sd for each
#ggplot(cat_stats, aes(x = fct_reorder(Category, mean_owned), y = owned)) + geom_boxplot( fill = wes_palette(n=5, name="FantasticFox1")[3]) + labs(title = "Number of Users Owning Game by Category") + scale_x_discrete(name="Board Game Category")  + scale_y_continuous(name = "Number of Users Owning Game")

```



```{r}

ggplot(cat_stats, aes(x = fct_reorder(Category, mean_wishing), y = mean_wishing)) + geom_bar(position = position_dodge(), stat = 'identity', fill = wes_palette(n=5, name="FantasticFox1")[3]) + geom_errorbar(aes(ymin = mean_wishing - sd_wishing, ymax = mean_wishing + sd_wishing), width = .2) + coord_flip() + labs(title = "Average Number of Users with Game on Wishlist by Category") + scale_x_discrete(name="Board Game Category")  + scale_y_continuous(name = "Average Number of Users with Game on Wishlist")

```



Scatter plot of mean rating and mean owned/wishing? Or median?

```{r}
ggplot(cat_stats, aes(x = mean_rating, y = mean_owned)) + geom_point() + 

ggplot(cat_stats, aes(x = mean_rating, y = mean_wishing)) + geom_point()

ggplot(cat_stats, aes(x = median_rating, y = median_wishing)) + geom_point()
```

```{r}
model_ro = lm(owned ~ average, games)

summary(model_ro)

model_rw = lm(wishing ~ average, games)

summary(model_rw)

#neither of them are really great but average seems to explain rating better than it explains owned.

#i know i can use category but its gonna be annoying but i should do it

```

Maybe should also look at the tippy top most owned/wished for games and see what they have in common?

```{r}
games %>%
  filter(owned > 2000) %>%
  ggplot(aes(x=owned)) + geom_histogram()

summary(games)

#owned mean is much higher than median.

games %>%
  arrange(desc(owned))
#9 games have over 100k people saying they own them but the mean is about 1500, and median like 300 data is really skewed.

cor(games$owned, games$wishing)

#owned and wishing are pretty correlated
#what if I do wishing and remove all with 0. started with 21,625 games.

games %>%
  filter(wishing >0 & owned > 0)
  #summary()

#only drops like 100 lol




```

